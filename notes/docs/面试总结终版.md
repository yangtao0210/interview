# 一、MYSQL

## **1.MYSQL的索引**

### 1.1 概述

```mysql
1)索引是存储引擎快速查找记录的一种数据结构，在存储引擎中实现;
2)使用索引的主要目的就是优化查询速度;
3)索引中存储对数据表中所有记录的引用指针,索引以文件的形式存储在磁盘中。
### 优势
# 1.提高语句查询效率，减少IO操作次数；
# 2.索引列会进行排序，使用分组和排序子句查询时，可以显著减少查询时间
### 缺点
# 1.索引文件需要占用物理空间
# 2.创建和维护索引比较耗时
# 3.索引需要动态维护，会降低数据更新效率
```

### 1.2 分类

```MYSQL
1.单列索引：
    普通索引:允许空值 & 重复值
    唯一索引:允许空值 & 不可重复
    主键索引:不允许空值 & 唯一
2.组合索引：在表中的多个字段上创建索引，遵循最左前缀原则；
## MyIsam引擎支持
3.全文索引：MyIsam引擎中使用，只能在 char,varchar,text 字段类型上使用。
4.空间索引：MySQL 在 5.7 之后的版本支持了空间索引
## Memory引擎支持
5.哈希索引：基于哈希表实现【无法用于排序、不支持部分索引匹配、不支持范围查找】
6.覆盖索引：可以避免二级索引的回表查询。【覆盖是指查询的字段都是索引字段】
```

### 1.3 索引内存模型

#### 1.3.1 哈希表

```mysql
以键值对存储数据的结构。
	key 用于存储索引列；
	value 就是某行的数据或者是它的磁盘地址。
## 底层结构：数组 + 链表实现
## 存在问题
# 无法用于排序、不支持部分索引匹配、不支持范围查找
```

#### 1.3.2 有序数组

```mysql
主要解决区间查询慢的问题，适用于存储不经常变动的数据,新增数据的成本太高。
## 底层主要通过二分查找来提高查询效率。
```

#### 1.3.3  B树

```mysql
思想 : 通过减少树的高度，来减少磁盘的访问次数，通过扩展树的分支来降低树的高度，从而提高查询效率。
说明：
	InnoDB 存储引擎一次IO会读取一页(默认16k)数据，二叉树一次IO有效数据量为只有16个字节，空间利用率极低，为最大化利用一次IO空间，考虑在一个节点尽可能多的存储元素。根据页大小 & 一次IO的字节数 （ 16k / 16 = 1000）==>每个节点可以存储1000个索引。这样一来，1百万条数据只需要2层就可存储（只需要2次操作就可以查询到全部数据）
### 存在问题
# 1.叶子节点无指针相连，范围查询时会增加磁盘的IO次数，查询效率低。【范围查找过程为:从根节点开始先查找左边界，再从根节点开始查找右边界】
# 2.如果data存储的是行记录，行所占空间会随着列数的增多而变大，因为页大小固定，此时，一个页中可存储的数据量会变少，树会变高，IO次数会增多，效率变低。
```

#### 1.3.4 B+ 树

```mysql
与B Tree有两点不同：
1）B+ Tree的非叶子节点不存放数据，只存放键值；B Tree叶子 & 非叶子节点都存放数据
2）B+ Tree的叶子节点之间通过双向指针相连，构成双向有序链表。
### 存在疑问：B+ Tree的数据都存在于叶子节点，只有遍历到叶子节点才能查出数据，而B Tree 不需要遍历到叶子节点就可以查询到数据，效率不是变慢了吗？
### 解答：B+ 树非叶子节点只存储键值，键所需存储空间比数据少的多，在页大小固定的情况下，每个节点就可以存储更多的索引，此时，索引树的高度会降低，磁盘IO操作变少，查询效率会有所提高。**
```

### **<font color = yellow> 1.4 MYSQL 索引是如何执行的</font>**

#### 1.4.1 聚簇索引（主键索引、一级索引）

```mysql
使用B+ Tree构建,叶子节点存储数据表的某一行数据。当表没有创建主键索引时,Innodb引擎会自动创建row_id作为数据表的主键索引。
```

**存储结构**

![image-20210722200143366](..\pictures\image-20210722200143366.png)

**索引查找执行流程：<font color = yellow>可以利用叶子节点之间构建的双向有序链表提高效率</font>**

![image-20210722200844600](..\pictures\\image-20210722200844600.png)

#### 1.4.2 非聚簇索引（二级索引、辅助索引、普通索引）

```mysql
使用B+ Tree构建,叶子节点 & 非叶子节点均存储键值，需要进行‘回表’查询。
```

**存储结构**

![image-20210722201304132](..\pictures\image-20210722201304132.png)

**查找流程：<font color = yellow>需要进行回表查询</font>**

![image-20210722201716561](..\pictures\image-20210722201716561.png)

## **2.MYSQL事务**

### 2.1  概念 & 特性

```MYSQL 
1.事务是什么？
	1）一组数据操作，要么全部成功、要么全部失败。一部分操作失败时，会回滚所有操作。
	2）事务在引擎层实现。 Innodb 引擎支持、MyIsam不支持。
2.ACID特性
	1）原子性(Atomicity)：事务开始后所有操作，要么全部做完，要么全部不做。
	2）一致性(Consistency):事务开始前和结束后，数据库的完整性约束没有被破坏。
	3）隔离性(Isolation):同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。
	4) 持久性(Durability):事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。
```

### 	2.2 并发问题

```mysql
1.脏读：事务 A 读取了事务 B 更新的数据，然后 B 进行了回滚，那么 A 读取到的数据是脏数据。
2.不可重复读(数据更新导致)：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。
3.幻读(数据增加、删除导致)：事务 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级, 事务 B 就在这个时候插入了一条记录，事务 A 修改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。
```

### 2.3 隔离级别----解决并发问题

|                         事务隔离级别                         | 脏读  | 不可重复读 | 幻读  |
| :----------------------------------------------------------: | :---: | :--------: | :---: |
|                **读未提交(Read-Uncommited)**                 | **√** |   **√**    | **√** |
|                 **读提交（Read-Commited）**                  | **×** |   **√**    | **√** |
| **可重复读（Repeatable-Read）<font color = red >默认级别</font>** | **×** |   **×**    | **√** |
|                  **串行化（Serializable）**                  | **×** |   **×**    | **×** |

### 2.4 设置事务隔离级别

```mysql
### 1.查看事务隔离级别
    # 5.7.20之前
    show variables like 'transaction_isolation';
    # 5.7.20及之后
    show variables like 'tx_isolation';
### 2. 设置隔离级别
	# set [作用域] transaction isolation level [隔离级别]：设置全局隔离级别为‘读提交’
	set global transaction isolation level read committed; 
### 3.启动事务
	# 1）显式启动【一致性视图在执行第一个快照读时创建】
	start / begin transaction;    #开启事务,执行到第一条sql语句时，事务才真正启动。
	update student set name = '张三' where id = 2; #执行操作
	commit;                       #提交事务
	# 2）set autocommit = 0 : 关闭事务的自动提交，执行sql语句时会启动事务，直到commit / rollback
	# 3) set autocommit = 1 : 开启事务的自动提交，执行单个sql语句时会启动 & 提交事务；多个语句需要手动开启 & 提交事务。
	# 4）start transaction with consistent snapshot:立刻启动事务。
```

### 2.5 隔离级别的实现原理

#### 2.5.1 MVCC 多版本并发控制

##### 1. 概述

```mysql
1.概念：MVCC 使得数据库读不会对数据加锁，普通的 SELECT 请求不会加锁，提高了数据库的并发处理能力；数据库写才会加锁。
2.说明：MVCC 只能实现 Repeatable Read & Read Committed 两种隔离级别. Read uncommitted 总是读取最新行，不符合当前事务版本的数据行; Serializable 会对所有读取的行加锁。
2.实现原理：在每行记录后面保存两个隐藏的列（trx_id,roll_ptr）来实现MVCC
    1） Innodb 的每个事务都有一个唯一的事务ID,记为 transaction_id,在事务开始时向 Innodb 引擎申请,按照时间先后严格递增。
    2）  依赖于 undo log,每行数据都存在多个版本。
    	a.每次事务更新数据会生成一个新的数据版本(trx_id),并将 transaction_id = trx_id;
    	b.将旧的数据版本保留在 undo log 中，而且通过 回滚指针roll_ptr 链接前一个版本。
```

##### 2. Undo Log

```mysql
### insert undo log
1) insert 操作产生的 undo log;
2) insert 操作没有历史版本，只对当前事务本身可见，对其他事务此记录不可见,insert undo log在事务提交后直接删除，不需要进行 purge 操作。
	# purge 操作：将数据库中已经 mark del 的数据删除，另外也会批量回收 undo pages
### update undo log
1) UPDATE 和 DELETE 操作产生的 Undo log;
2) update 可以视为 insert 新数据到原位置，delete 旧数据，undo log 暂时保留旧数据.
```

##### 3. Read-View（一致性视图）

```mysql
### 说明：
1) Innodb 在实现MVCC时用到的 一致性视图，用于支持 RC & RR 隔离级别的实现；
2) 不真实存在,通过 undo log 体现，作用是决定事务能够看到哪些数据。【主要包含当前系统中还未提交的读写事务】
3) 每个事务或语句都有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 trx_id 和一致性视图确定数据版本的可见性。
```

###### 数据版本可见性解决方案

```mysql
### 说明：把系统中已提交的事务 ID 的最大值记为数组的低水位（low_id），已创建过的事务 ID + 1 记为高水位(up_id)。视图数组 & 高水位 组成当前事务的一致性视图（read-view）
### 可见性规则：
1) trx_id < low_id:表示生成该版本的事务在生成 read view 前已经提交，所以该版本可见，可以被当前事务访问;
2) trx_id > up_id：表示生成该版本的事务在生成 read view 后才生成，所以该版本不可见，不能被当前事务访问;
3) low_id <= trx_id <= up_id : 存在两种情况
	a) trx_id 在视图数组中，证明这个版本是由还未提交的事务生成的，不可见
	b) trx_id 不在视图数组中，证明这个版本是由已提交的事务生成的，可见	
### 注释：视图是否可见，主要看创建视图 & 提交事务的时机
```

![image-20210724152737155](..\pictures\image-20210724152737155.png)

## **3.MYSQL锁**

![image-20210723095951530](..\pictures\image-20210723095951530.png)

### 3.1 全局锁

**<font color = red>注释：</font><font color = yellow>InnoDB引擎中，可使用事务RR隔离级别代替</font>**

#### 3.1.1 概念 & 语法

```mysql
全局锁是对整个数据库实例加锁，让其处于只读状态。加全局锁后，DML & DDL 等操作将被阻塞。
### 实现(FTWRL)
Flush tables with read lock
### 解除只读状态
unlock tables
```

#### 3.1.2 应用场景

```mysql
全库逻辑备份：将数据库的所有表 select 出来存储为文本。 【FTWRL定时备份 + binLog恢复增量数据】
数据库处于只读状态，会存在两个问题：
	1）主库备份：备份期间数据不能写入，业务会受影响；
	2）从库备份：备份期间不能执行主库同步过来的 binlog,会导致主从延迟，业务会受影响。
```

#### 3.1.3 为什么要加锁？

```MYSQL
不加锁的话，会导致备份所得到的库，与开始备份的库，不是同一个逻辑时间点。【在备份的过程中，有新的数据插入、删除或更新，导致主从不一致】
```

#### 3.1.4 使用readonly = 1 的方式使全库只读是否可行？

```mysql
### sql 设置全库只读，不能使用
set global read_only = 1;
### 设置全库只读存在问题：
	1) 影响业务逻辑：在读写分离场景下，该语句可能会用于一些业务判断；
	2）异常时不释放状态：FTRWL 命令在异常发生时，会自动释放全局锁；set global read_only = 1 异常时，会一直保持只读状态。
	3）该命令对超级管理员无效。若在备份期间，超管更新数据，会导致数据不一致问题。
```

### 3.2 表级锁

#### 3.2.1 表锁

```mysql 
###  语法 
# 加锁
lock tables t1 read / write,t2 read / write;
# 释放锁
unlock tables;
```

#### 3.2.2 元数据锁（MDL）

```mysql
### 说明： 隐式使用，访问表时(执行语句时加锁,事务提交后释放)系统会加上，MYSQL5.5 版本引入;
### 主要作用： 防止DDL(修改表结构) & DML（CRUD表数据）并发的冲突。
### 实现逻辑：
	1.对 DML(增删改查) 操作，加MDL读锁;
	2.对 DDL 操作，加MDL写锁;
1)读读不互斥：可以多线程对一张表增删改查;
2)读写 & 写写互斥：保证对表结构操作时，只能有一个线程，其他线程阻塞。
```

### 3.3 行锁

```mysql
### 概念：行锁就是针对表中行记录的锁。
### 说明：
	1)在存储引擎中实现;
	2)事务A先更新一行，同时事务B也要更新同一行，则事务B必须等待事务A操作完成后才能进行更新。
```

#### 3.3.1 两段锁协议

```mysql
### 两段锁协议：分为加锁 & 释放锁阶段，所有的lock操作都在unlock之后。
### 说明：
	1）根据两段锁协议，对于高并发的行记录操作应该尽可能安排到最后面，以减少行锁的等待时间，提高系统并发性能。
	2）释放锁发生在事务提交之后。
```

#### 3.3.2 死锁

```mysql
### 概念：不同线程出现循环资源等待，涉及的线程都在等待其他线程释放资源，会导致这几个线程进入无线等待的状态，成为死锁。
```

#### 3.3.3 如何解决死锁？

##### 1. 加入等待时间

```mysql
### 设置超时时间参数
set global innodb_lock_wait_timeout = 500;
### 思想:直接进入等待，直到超时。
### 存在问题：超时时间无法确定
```

##### 2. 检测死锁，主动回滚事务

```mysql
### 设置开启死锁检测
set global innodb_deadlock_detect = on;
### 思想：循环依赖检测，判断是否存在死锁
### 存在问题：在检测死锁期间，会消耗大量的CPU资源。
```

##### 3.解决热点行更新问题

```mysql
通过控制服务端的并发度（限流），来减少死锁检测的CPU压力。
```

## **4.MYSQL引擎**

### 4.1  缓冲池

- **缓存池的作用**

  ```mysql
  由于CPU的处理速度和磁盘的IO速度之间差距太大，为提高整体效率，InnoDB向操作系统[本质：申请的一段连续的内存空间]，作为缓冲池。
  ```

- **缓存池的结构**

  ```mysql
  内部主要通过链表实现：
      Free List：存储未被使用的页节点，若FreeList不够用，需要从LRU/FLU List上淘汰一定的节点；
      LRU List：存储新读取的数据页
      FLU List:存储脏页（被修改过，还未刷新到磁盘上的页）
  	Quick List:存储带有Hint的SQL语句用到的数据页，SQL语句结束就淘汰对应的页。
  ```

- **存在问题：缓冲池污染 & 预读失效**

  ```mysql
  1.缓冲池污染
      概念:当SQL语句要批量扫描大量数据时（只访问一次），可能会把缓冲池中所有页都替换出去，会导致大量热数据页被换出，MySQL性能急剧下降。
      解决方案：新老生代改进版LRU+“老生代停留时间窗口”T 机制
  2.预读失效
      概念：预读（Read-Ahead）时,提前将页放入缓冲池，但最终Mysql并没有从预读页中读取数据；
      解决思路：
          让预读失败的页，停留在缓冲池LRU里的时间尽可能短
          让真正被读取的页，挪到缓冲池LRU的头部【保证真正被读取的热数据留在缓冲池的时间尽可能长】
  ```

## **5.MYSQL日志**

### 5.1 事务日志 redo - log

### 5.2 归档日志 binLog

## **6.高频面试题**

### 6.1主键自增问题

#### 6.1.1 自增主键为何不用varchar?

```mysql
UUID是 32个字符+4个'-'组成，长度为36,虽然UUID可以保证唯一性，但是有两个致命的缺点：
	1)UUID不是自增的，插入可能会导致页分裂，树高度增加，性能下降。
    MYSQL中索引的数据结构是B+树，这种数据结构的特点是索引树上的节点数据有序，如果使用UUID作为主键，每次插入数据时，因为无法保证每次产生的UUID有序，所以会出现新的UUID插入到索引树的中间去，频繁导致页分裂，使得性能下降。
    2)太占用内存。
    ① 字符串需要从前向后比较，字符串越长，性能就越差；
    ② 字符串比较占用内存，数据页的大小是固定的，主键越长，能存储的数量就越少，最终会导致索引树的高度越大，在索引搜索时发生磁盘IO的次数就越多，导致性能下降。
```

#### 6.1.2 自增ID用完了怎么处理？

**<font color = yellow>分两种情况讨论</font>**

> **1）声明了自增主键：报主键冲突错误**
>
> ```mysql
> 1）将主键类型修改为 bigint 类型,8 个字节（ 2 ^ 64 - 1位）。
> 2）一般情况下，数据量达到500万时就应该考虑分库分表。
> ```
>
> **2）未声明自增主键：新数据会覆盖旧数据**
>
> ```mysql 
> Innodb会自动创建一个不可见的、长度为6个字节的row_id(bigint unsigned类型);
> Innodb会维护了一个全局的dictsys.row_id,未定义主键的表都共享该row_id,插入一条数据，都会把row_id当成主键id,然后 +1。
> 
> 如果全局row_id一直涨，涨到 2 ^ 48 - 1时，这个时候再+1, row_id 的低48位都为0，在插入新一行数据时，拿到的row_id就为0，再插入时会覆盖之前的值。
> ```

### 6.2 InnoDB在RR级别可以解决幻读，为何还要Serializable隔离级别?

```mysql

```



------

# 二、Java基础

## 1.HashMap & ConcurrentHashMap

### **1.1 底层结构**

```java
"Map 相关参数"：
{
    //1.初始化容量：16
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; 
    //2.最大容量：1073741824
    static final int MAXIMUM_CAPACITY = 1 << 30;
    //3.加载因子(扩容因子)：默认0.75
    static final float DEFAULT_LOAD_FACTOR = 0.75f;
    //4.当链表长度大于此值且容量大于 64 时，转换为红黑树结构
	static final int TREEIFY_THRESHOLD = 8;
    static final int MIN_TREEIFY_CAPACITY = 64;
    //5.转换链表的临界值，当元素小于此值时，会将红黑树结构转换成链表结构
    static final int UNTREEIFY_THRESHOLD = 6;
}
HashMap底层结构（JDK 1.7 & 1.8）
/**JDK 1.7版本：数组 + 链表**/
/**JDK 1.8版本：数组 + 链表 & 红黑树 **/
ConcurrentHashMap底层结构【JDK 1.7 & 1.8】
/**
JDK 1.7 : 
	1.实现原理：分段锁(Segment,继承于ReentrantLock) + HashEntry + 链表;
	2.参数说明：Segment
		1) 一个静态内部类;
		2) 默认为16个，即默认并发度为16;
		3) 由 volatile 修饰,保证多线程环境下的数据可见性。
	3.缺点：查询遍历链表的效率太低
JKD 1.8 : CAS + Synchronized + Node + 红黑树
	说明：
		1）为保证序列化时的兼容,内部仍然具有Segment的定义;
		2) 使用lazy-load形式来避免初始化开销;
	1.实现原理：CAS + Synchronized + volatile 
		1）使用volatile保证数据的可见性;
		2）使用CAS操作,在特定场景下进行无锁并发操作,提高并发性能;
		3）使用CAS + synchronized将锁粒度控制在table元素级别。
	2.sizeCtl参数：用于表初始化和调整大小
*/
```

![image-20210728235936084](..\pictures\image-20210728235936084.png)

![image-20210729000400350](..\pictures\image-20210729000400350.png)

### 1.2底层实现

#### 1.2.1 put()

```java 
1)调用 putVal() 添加元素;
2)判断 table 数组是否为空 || 长度为0：
     若为空：调用 resize()初始化数组;
	 若不为空：根据 key 计算 hash值【hashCode ^ hashCode >>> 16】,计算元素在 table 的下标 index = hash & (n-1),执行步骤 3);
3)判断 index 是否存在数据：
    index 位置不存在数据:构造Node节点,存入table[index];
    index 位置存在数据：执行步骤 4);
4)判断当前节点的key与待插入节点的key是否相等：
    若相等：更新该节点的value,并返回旧value;
	若不相等：执行步骤 5);
5)判断当前节点是否为红黑树节点：
    若是：执行步骤 6);
	若否：执行步骤 7);
6)调用 putTreeVal()方法将节点插入红黑树,判断节点数是否大于扩容阈值:
	若大于：调用 resize() 扩容 & 迁移元素;
7)遍历链表,根据key判断 更新 OR 插入节点,插入后判断节点数量是否大于建树阈值：
    若大于：将链表转为红黑树;
8)操作完成后,modCount+1,结束。
```
![image-20210719172116629.png](..\pictures\image-20210719172116629.png)

#### 1.2.2 resize()

```java
思想：重写规划长度和阈值，如果长度发生了变化，部分数据节点也要重新排列
重新规划长度：
    1)如果当前容量oldCap > 0 & 达到最大值，将阈值设为Integer的最大值，return终止扩容；
    2)如果未达到最大容量，当oldCap << 1 不超过最大容量时,就扩大2倍；
    3)如果都不满足且当前扩容阈值 oldThr > 0,使用当前扩容阈值作为新容量；
    4)否则将新容量置为初始容量16,新扩容阈值置为12。
重写排列数据节点：
    1)如果节点为null：不进行处理;
    2)如果节点不为null & 没有next节点，通过[节点的hash & (新容量-1)]计算出节点在table数组中的下标;
    3)如果节点为TreeNode类型，调用split方法处理，如果节点数hc达到6，调用untreeify方法转回链表;
    4)如果是链表节点，需要将链表拆分为[hash值超出旧容量 & hash值未超出旧容量]的链表，对于hash & oldCap == 0 的部分不做处理，否则将节点放在新下标的位置。[新下标 = 旧下标 + 旧容量]
```

### 1.3 HashMap线程不安全

```Java
1.数据丢失【JDK 1.7 & 1.8均存在】:
	①并发赋值被覆盖：两个线程同时修改同一个key,后一个的修改会覆盖前一个的修改;
	②已遍历区间新增元素丢失：在transfer迁移过程中，其他线程在已遍历区间的哈希槽中新增数据，遍历完成后，table数组引用指向newTable,新增元素丢失;
	③新表被覆盖:resize完成后，table = newTable,后续元素会在newTable上插入。如果多个线程同时resize,因为newTable是线程私有的局部变量，后面线程的newTable可能会覆盖之前线程的newTable,导致前一个线程在newTable上插入的元素被覆盖。
2.死循环【JDK 1.7存在,1.8不存在该问题】
     resize() 扩容时调用transfer方法转移元素时使用头插法，由于原table共享，若多个线程对next指针进行并发修改，其中某个线程还没有将table = newTable时，时间片用完，多线程就会陷入死循环。
```

## 2.HashMap & HashTable & ConcurrentHashMap

```java 
1.HashMap
	1) 实现了 Map接口;
	2) 允许键 和 值 为 null;
	3) 不允许重复键,允许重复值;
	4) 线程不安全。
2.HashTable
	1) 实现了Map接口;
	2) 不允许 键或值 为 null;
	3) 使用 synchronized 方法,实现线程安全;
3.ConcurrentHashMap
	1) 满足高效 & 线程安全;
	2) 不允许 键 为 null;
	3) 通过分段锁Segment实现高并发 & 线程安全	
        原理：将Map分为N个Segment,对每一个Segment加锁
```

## **3. String & Stringbuilder & Stringbuffer**

```java
相同点：底层实现都是字符数组char[] values;
1.是否可变长： String 不可变[final 修饰],StringBuilder & StringBuffer 可变长;
2.线程安全性:  String 是常量[final 修饰]线程安全;StringBuffer 线程安全[synchronized 关键字修饰方法];StringBuilder 线程不安全[未用 synchronized 关键字修饰];
3.性能方面： StringBuilder > StringBuffer > String;

/**扩展：
	1.final & finally & finalize
		1)final 修饰类不可被继承,修饰属性不可变,修饰方法不可重写;
		2)finally 异常处理语句结构，表示总是执行;
		3)finalize 是 Object类的一个方法,在垃圾收集器执行时调用此方法回收对象。
*/
```

## 4. 接口与抽象类

```java
1.变量：接口的所有变量默认为final（ public static final varName）,抽象类中可包含非 final 变量;
2.方法：接口的所有方法默认为 public abstract,抽象类中可包含非抽象方法 & 修饰符可以是 public、protected、private;
3.接口和抽象类都不能被实例化;
4.JDK 1.8 之后,接口 & 抽象类都可以包含 static 方法,JDK 1.8之前接口中不能有 static 方法。 
```

## 5.ArrayList & LinkedList 

```java
1. 底层实现：
    ArrayList 实现了 List & RandomAccess接口,且继承了AbstractList抽象类;底层是基于数组实现 & 支持动态扩容; 
    LinkedList 实现了 List & Deque 接口,且继承了AbstractSequentialList抽象类;底层基于双向链表实现。
2.关键参数:
	ArrayList:
        1)数据域为： transient Object[] elementData,size(实际大小)
        2)writeObject() & readObject() 完成序列化和反序列化。
    /**
    	疑问1：ArrayList通过实现Seralizable接口实现序列化，为什么数据域elementData 又不能序列化?
    	大概思路：
        1）ArrayList的扩容机制是：在添加元素时,发现数组容量已满，会重新开辟原始容量1.5倍的内存空间 & 将原始数组的元素复制到新分配的内存地址上，从而实现动态扩容;
        2) 这样一来,elementData数组是无法被填满的,闲置空间会随着元素数量增加,序列化时会耗费大量的时间来处理闲置空间。
        序列化：
    */
     LinkedList：
            transient int size, Node<E> first, Node<E> last;    
3.优势：
    ArrayList 支持随机访问[原因：实现了RandomAccess接口，通过索引方式访问],但插入和删除速度慢,适用于存储数据基本不变动的场景;
	LinkedList 插入和删除速度快，但不支持随机访问,适用于更新频繁的场景;内存利用率高 
```

## 6.浅拷贝 & 深拷贝

### 5.1 浅拷贝

**说明：对基本数据类型进行值传递，对引用数据类型进行引用地址的拷贝；**

```json
所复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用仍然指向原来的对象。
对象的"浅拷贝"会对“主”对象进行拷贝，但不会复制主对象里面的对象("引用的对象"-"会在主对象与其副本之间共享")
```

![image-20210718140049026](..\pictures\image-20210718140049026.png)

### 5.2 深拷贝

**说明：对基本数据类型进行值传递，对引用数据类型，创建一个新对象，并复制其内容。**

```json
深拷贝是一个整个独立的对象拷贝，深拷贝会拷贝所有的属性,并拷贝属性指向的动态分配的内存。当对象和它所引用的对象一起拷贝时即发生深拷贝。"深拷贝会把要复制的对象及其所引用的对象都复制一遍"。
```

![image-20210718135943143](..\pictures\image-20210718135943143.png)



------

# 三、并发编程

## 1.Java 锁

### 1.1谈谈Java锁

```java
锁的出现：并发编程中，当多个线程对同一个共享变量进行读写操作时，会产生数据不一致的问题，可以通过锁来解决；
锁的分类：锁可以按照不同的标准分为以下几类
	1)可重入锁 & 不可重入锁:同一线程在外层方法中获得锁，进入内层方法时会自动获取锁;
	2)乐观锁 & 悲观锁 ： 线程在处理共享数据时先不加锁，更新数据时判断是否需要加锁;
	3)公平锁 & 非公平锁 ： 锁的获取顺序按照请求的绝对时间顺序（遵循FIFO原则），获取锁时会判断当前节点的是否有前驱节点，等待其释放锁后，才能获取锁;
	4)独占锁 & 共享锁：锁一次是否只能被一个线程持有，若是：为独占锁（synchronized & ReentrantLock），否则为共享锁;
	5)读写锁：维护一个读锁和写锁，通过分离读写操作来提高并发性，其实现依赖AQS(抽象队列同步器)，其读写状态就是同步器的同步状态【int变量的高16、低16位分别表示读和写线程状态】
        涉及锁降级问题：保持当前写锁，再次获取读锁，随后再释放先前拥有的写锁。
        不直接释放写锁，获取读锁原因：保证数据的可见性【如果先释放写锁，假设此时另一个线程A获得写锁并修改了数据，当前线程无法感知线程A的数据更新】
    6)自旋锁 & 适应性自旋锁
 		自旋锁：尝试获取锁的线程不会立即阻塞，会采用循环的方式重新尝试获取(默认自旋10次)；
         适应性自旋锁：自旋时间不固定，由前一次的自旋时间和锁的拥有者决定。如果在同一个锁上，通过自旋刚刚成功获取过锁且持有锁的线程正在运行，JVM会认为这次自旋很有可能成功，进而允许自旋持续更新，否则，直接放弃自旋，避免浪费资源。(经验值自旋)
    7)无锁 & 偏向锁 & 轻量级锁 & 重量级锁【锁的状态】
          无锁(01 & 是否为偏向锁 = 0):未对资源进行锁定，所有线程都能访问并修改同一资源【修改操作在循环内执行，线程会不断尝试修改共享资源】，但只有一个线程能够修改成功；
          偏向锁(01 & 是否为偏向锁 = 1):同一段代码同时被一个线程访问，该线程会自动获取锁，降低获取锁的代价【不存在多线程竞争问题,JDK 6之后默认启用】
          轻量级锁(00):当前锁为偏向锁 & 被另一个线程访问时，会升级为轻量级锁，另一个线程会通过自旋的方式尝试获取锁，不会阻塞，从而提高性能；
          重量级锁(10):若当前只有一个线程等待，则该线程通过自旋等待，当自旋超过一定次数 || 此时有另一线程请求锁时，轻量级锁升级为重量级锁。
```

- **非公平锁是怎么处理阻塞的，新进来的线程怎么做？**

### 1.2 ReentrantLock & Synchronized

#### 1.2.1 谈谈Synchronized

```java
1.修饰范围：
	1)实例方法：作用于当前对象实例加锁，进入同步代码前要获得当前实例对象的锁;
	2)静态方法：作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁;
	3)代码块：指定加锁对象，对给定对象加锁，进入同步代码块前要获得给定对象的锁。
2.底层原理:
	1)代码块： synchronized 同步代码块使用 monitorenter & monitorexit指令;
	2)方法： synchronized 同步方法使用 ACC_SYNCHRONIZED 标识，指明该方法是一个同步方法，JVM通过该标识辨别一个方法是否声明为同步方法，执行同步操作。
3.JDK 1.6的优化
	引入自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁和轻量级锁等技术来减少锁操作的开销。
```

#### 1.2.2谈谈ReentrantLock

```java 
1)底层通过AQS + CAS 实现，使用共享资源volatile State作为同步状态变量;
2)ReentrantLock通过调用AQS的getState、setState、CompareAndSetState三个方法来管理State同步状态，从而实现公平锁 & 非公平锁 lock & unlock;
3)实现Lock接口，并构造了三个内部类[继承自AQS的Sync类、继承自Sync的FairSync & NonfairSync,分别实现公平锁 & 非公平锁。
```

- **公平锁实现**

  ```Java
  1.获取状态state，若state == 0 ：代表锁没有被其他线程占用[同步队列中可能有线程等待]，执行2；否则，执行3;
  2.state == 0:判断同步队列是否存在线程(节点)，若不存在，直接将锁的所有者设置成当前线程，且更新state状态，返回true;否则,加入等待队列并返回false;
  3.判断锁的所有者是不是当前线程，若是，则更新state状态，返回true;否则，将当前线程加入同步队列等待并返回false。
  ```

  ![image-20210721095733954.png](..\pictures\image-20210721095733954.png)

- **非公平锁实现**

  ```java
  1.调用CAS设置state的值：若state == 0，将其设置为1，并执行 setExclusiveOwnerThread() 方法将当前线程设置为锁的所有者；若CAS设置失败，代表锁被占用，执行 acquire(1);
  2. acquire(1):重写 tryAcquire()，内部调用 boolean nonfairTryAcquire().
      nonfairTryAcquire() 内部执行流程：
      1)调用getState方法获取state的值：
      	若state == 0:将 state 设置为1，并执行 setExclusiveOwnerThread()方法将当前线程设置为锁的所有者；
      	若state != 0:调用 getExclusiveOwnerThread() 方法查看占用锁的线程是否为当前线程，若是，则将 state + 1 并返回 true;否则返回false,线程进入同步队列。 
  ```

  ![image-20210721095617360.png](..\pictures\image-20210721095617360.png)

#### 1.2.3 比较Synchronized & ReentrantLock

```java
1)两者都是可重入锁，自己可以再次获取自己的内部锁；
2)synchronized 依赖于JVM;ReentrantLock依赖于API(JDK),需要通过lock & unlock方法配合try/finally语句块完成。
3)ReentrantLock 比 synchronized增加了一些高级功能：
    等待可中断：通过lock.lockInterruptibly()来实现【正在等待的线程可以选择放弃等待】；
    可实现公平锁；而 synchronized 是非公平的【原因：所有收到锁请求的线程⾸先⾃旋，如果通过⾃旋也没有获取锁将被放⼊ ContentionList，该做法对于已
经进⼊队列的线程不公平。】
    可实现选择性通知（锁可以绑定多个条件）：线程对象可以注册到指定的Condition中，实现选择性的线程通知，在调度上更加灵活；
    性能不是区分 synchronized & ReentrantLock的标准：JDK 1.6之前 synchronized 的吞吐量会随着线程数的增加而急剧下降，JDK 1.6之后，性能基本持平。
```

## 2.AQS



## 3.JUC包

### 2.1CAS实现原理？什么情况下使用CAS？ABA问题及解决方案

```java
本质都是调用 compareAndSwapInt(obj,offset,expect,update):如果obj的 value 和 except相等，就将其更新为update,若CAS未成功，就自旋CAS。
ABA问题就是：线程读取时变量x的值为a,此时，另一个线程将变量x的值先变为b,又变回a,之后第一个线程对变量x进行CAS操作成功。
解决方案：atomic包中的AtomicStampedReference通过添加版本号解决该问题。
```

##  4.多线程

### 4.1三种实现方式

```Java
1）继承Thread类，并重写其run()方法   
public class testThread extends Thread{
    @Override
    public void run(){
        //具体实现
    }
}
"使用":new TestThread().start();
2）实现Runnable接口,并重写其run()方法
public class testThread implements Runnable{
    @Override
    public void run(){
        //具体实现
    }
}
"使用":作为Thread的参数使用，new Thread(new TestThread1()).start();
3）实现Callable接口，并重写其call()方法【有返回值】
class TestThread2 implements Callable{
    @Override
    public Object call() throws Exception {
        System.out.println("实现Callable接口......");
        return null;
    }
}
"使用"：new FutureTask<Object>(new TestThread2()).run();
```

### 4.2为什么使用多线程

```json
程序中有很多操作时非常耗时的【数据库的读写、IO操作等】，如果使用单线程，程序就必须等这些操作完成后才能执行其他操作。使用多线程可以将耗时任务放在后台继续执行，同时执行其他操作，提高系统的性能及CPU的利用率。
```

### 4.3什么时候使用多线程

```Java
/**注意:多线程可以更加充分地利用CPU的资源,不会增加CPU的处理性能*/
是否使用多线程很大程度上取决于应用程序的类型;
多线程的应用场景：
    1）IO密集型任务：IO操作比较耗时，当程序在等待资源的过程中，可以使用多线程来执行其他操作，提高系统性能；
    2）并行任务：C/S架构中，服务器端可以通过并行任务来处理用户的请求，提高响应速度；
    3）多CPU系统中，可以使用多线程提高CPU的利用率；
```

## 5.线程池

### 5.1核心参数

```java
七个：核心线程数、最大线程数、非核心线程的最大存活时间、空闲存活时间单位、工作队列、创建线程的工厂、饱和策略
```

### 5.2线程池类型

```Java
newCachedThreadPool:可缓存线程池【核心线程数为0，最大线程数为 Integer 的最大值，空闲存活时间为60s,无容量的同步队列】
newFixedThreadPool:固定工作线程数量线程池【核心与最大相等，无空闲存活时间，无界队列】
newScheduleThreadPool:定长定时周期线程池【最大线程数为 Integer 的最大值，无空闲存活时间，延迟队列】
newSingleThreadExecutor：单线程线程池【核心线程数 & 最大线程数 = 1，无空闲存活时间，无界队列】
newWorkStealingPool：创建持有足够线程的线程池支持给定的并行度，通过多个队列减少竞争【JDK 8 引入】
```

### 5.3饱和策略

```java
AbortPolicy:抛出异常(默认策略)
DiscardPolicy:抛弃新提交任务
DiscardOldestPolicy:抛弃队列中最老任务，将当前任务加入任务队列
CallerRunsPolicy:将任务交于线程池调用的线程处理
```

# 四、JVM

# 五、设计模式

## **5.1 单例模式**

```java 
○ 饿汉式：在类加载时就初始化创建单例对象，线程安全，但不管是否使⽤都创建对象可能会浪费内存。
    public class HungrySingleton {

        private HungrySingleton(){}
        private static HungrySingleton instance = new HungrySingleton();

        public static HungrySingleton getInstance(){
            return instance;
        }
    }
○ 懒汉式：外部调用时才会加载，线程不安全，可以加锁保证安全性，但效率较低。
    public class lazySingleton {

        private lazySingleton(){}
        private static lazySingleton instance;

        public static lazySingleton getInstance(){
            if(instance == null){
                instance = new lazySingleton(); 
            }
            return instance;
        }
    }
○ 双重检测锁：使用volatile及多重检查来减小锁范围，提升效率
    public class DoubleCheckingSingleton {
        private DoubleCheckingSingleton(){}

        private volatile static DoubleCheckingSingleton instance;

        public static DoubleCheckingSingleton getInstance(){
            if(instance == null){
                synchronized (DoubleCheckingSingleton.class){
                    if(instance == null){
                        instance = new DoubleCheckingSingleton();
                    }
                }
            }
            return instance;
        }
    }
○ 静态内部类：解决饿汉的内存浪费和懒汉的线程不安全问题
    public class StaticSingleton {
        private StaticSingleton(){}


        public static StaticSingleton getInstance(){
            return StaticClass.instance;
        }

        private static StaticClass {
            private static final StaticSingleton instance = new StaticSingleton();
        }
    }

○ 枚举：Effective Java提倡方式，避免线程安全问题 & 防止反序列化重新创建新的对象 & 防止反射破解单例
    public enum EnumSingleton {
    INSTANCEOF;
}
```

## **5.2 职责链模式**

```java 
/**
 * 责任链模式（职责链模式）：
  优势：
     * 1.降低对象之间的耦合度
     * 2.增强系统的可扩展性
     * 3.增强对象指派职责的灵活性
     * 4.简化对象之间的连接
     * 5.责任分担
 *结构：
 *  抽象处理者Handler : 处理请求的接口，包含抽象处理方法和后继连接
 *  具体处理者Concrete Handler ：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者
 *  客户类 Client ： 创建处理链，并向链头的具体处理者提交请求，不关心处理细节。
 */
```

## **5.3  代理模式**

## **5.4  工厂模式**

# 六、Spring系列

## **6.1 IOC & AOP**

### **6.1.1 IOC：控制反转**

#### 1.实质

```java 
将原本在程序中手动创建对象的控制权，交由Spring框架管理。其底层是使用ConcurrentHashMap存储的键值对，key为字符串，value为BeanDefination对象。
```

#### 2.容器初始化过程

```java 
1.Resource资源（BeanDefinition）定位
		①设置加载器：调用父容器的构造方法为容器设置好Bean资源加载器；
		②资源定位：调用父类的setConfigLocation方法设置Bean配置信息的定位路径。
	2.BeanDefinition的载入和解析【refresh方法 & loadBeanDefinition方法】
		① 创建容器：调用父类AbstractApplicationContext的refresh方法启动IOC容器；
		② 资源 加载 & 解析：容器创建后，通过loadBeanDefinition方法加载并解析Bean资源【通过子类XMLBeanDefinitionReader解析配置文件路径、读取配置文件内容，并通过XML解析器将Bean配置信息转换为XML文档对象，并按照Spring Bean的定义规则对文档对象进行解析。】
	3.BeanDefinition注册【实质：IOC容器将解析的Bean信息存放在ConcurrentHashMap中，key为字符串，值为BeanDefinition，注册过程中使用synchronized保证线程安全。】
```

#### 3.依赖注入过程

```java 

```

### **6.1.2 AOP：面向切面编程**

#### 1.本质

```java
基于动态代理实现的，为减少代码冗余、降低模块间耦合度，利于系统可扩展和可维护性。
```

#### 2.初始化流程

```java 
1.注册自动代理器Creator,当做一个系统组件Bean；
2.解析配置元素，决定代理的模式【JDk 、CGLib】
3.将Creator放在Spring容器中，Spring实例化时，启动该代理器。
```

## 6.2 Spring 事务
